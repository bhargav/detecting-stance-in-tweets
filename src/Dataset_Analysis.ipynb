{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Analysis ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Stances =  ['FAVOR', 'NONE', 'AGAINST']\n",
      "Targets =  ['Atheism', 'Legalization of Abortion', 'Feminist Movement', 'Climate Change is a Real Concern', 'Hillary Clinton']\n",
      "Total Tweets = 2914\n",
      "Atheism 513 Counter({'AGAINST': 304, 'NONE': 117, 'FAVOR': 92})\n",
      "Legalization of Abortion 653 Counter({'AGAINST': 355, 'NONE': 177, 'FAVOR': 121})\n",
      "Feminist Movement 664 Counter({'AGAINST': 328, 'FAVOR': 210, 'NONE': 126})\n",
      "Climate Change is a Real Concern 395 Counter({'FAVOR': 212, 'NONE': 168, 'AGAINST': 15})\n",
      "Hillary Clinton 689 Counter({'AGAINST': 393, 'NONE': 178, 'FAVOR': 118})\n"
     ]
    }
   ],
   "source": [
    "from Model import Model as DataModel\n",
    "from collections import Counter\n",
    "\n",
    "dataset = []\n",
    "\n",
    "# for filename in [\"../dataset_raw/semeval2016-task6-trialdata.txt\", \"../dataset_raw/semeval2016-task6-trainingdata.txt\"]:\n",
    "#     f = open(filename, 'r')\n",
    "#     f.readline() # Skip the first line which contains the title\n",
    "\n",
    "#     for line in f.readlines():\n",
    "#         items = line.strip().split('\\t')\n",
    "#         t = DataModel(items[0] , items[1], items[2], items[3])\n",
    "#         dataset.append(t)\n",
    "\n",
    "targets_small_hack = ['atheism', 'climate change is a real concern', 'feminist movement', 'legalization of abortion', 'hillary clinton']\n",
    "targets_skip_index = [1, 6, 3, 4, 3]\n",
    "targets_real =  ['Atheism', 'Climate Change is a Real Concern', 'Feminist Movement', 'Legalization of Abortion', 'Hillary Clinton']\n",
    "\n",
    "f = open(\"../final.txt\", 'r')\n",
    "for line in f.readlines():\n",
    "    items = line.strip().split('\\t')\n",
    "    \n",
    "    for t in xrange(5):\n",
    "        if items[0].startswith(targets_small_hack[t]):\n",
    "            model = DataModel(None, targets_real[t], items[0][targets_skip_index[t]:], items[-1])\n",
    "            dataset.append(model)        \n",
    "        \n",
    "targets = list(set(map(lambda model:model.target, dataset)))\n",
    "stances = list(set(map(lambda model: model.stance, dataset)))\n",
    "\n",
    "print \"Stances = \", stances\n",
    "print \"Targets = \", targets\n",
    "print \"Total Tweets =\", len(dataset)\n",
    "for t in targets:\n",
    "    print t, len([_ for x in dataset if x.target == t]), Counter([x.stance for x in dataset if x.target == t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading the Stanford GloVe Twitter Embeddings learned over Twitter data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "glove_word_vec_file = \"../glove.twitter.27B/glove.twitter.27B.200d.txt\"\n",
    "\n",
    "def readGloveData(glove_word_vec_file):\n",
    "    f = open(glove_word_vec_file, 'r')\n",
    "    rawData = f.readlines()\n",
    "    word_vec_dict = {}\n",
    "    for line in rawData:\n",
    "        line = line.strip().split()\n",
    "        tag = line[0]\n",
    "        vec = line[1:]\n",
    "        word_vec_dict[tag] = np.array(vec, dtype=float)\n",
    "            \n",
    "    return word_vec_dict\n",
    "            \n",
    "word_vec_dict = readGloveData(glove_word_vec_file)\n",
    "\n",
    "def getWordVector(word):\n",
    "    if word in word_vec_dict:\n",
    "        return word_vec_dict[word]\n",
    "    return np.zeros_like(word_vec_dict['hi'])\n",
    "\n",
    "def getSumVectors(tweetData):\n",
    "    numNonZero = 0\n",
    "    vector = np.zeros_like(word_vec_dict['hi'])\n",
    "    \n",
    "    for word in tweetData:\n",
    "        vec = getWordVector(word)\n",
    "        vector = vector + vec\n",
    "        if vec.sum() != 0:\n",
    "            numNonZero += 1\n",
    "\n",
    "    if numNonZero:\n",
    "        vector = vector / numNonZero\n",
    "\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words in DataSet = 10163\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from nltk import TweetTokenizer\n",
    "\n",
    "tknzr = TweetTokenizer(strip_handles=True, preserve_case=False)\n",
    "\n",
    "word_counter = Counter()\n",
    "\n",
    "for tweet_model in dataset:\n",
    "    tweet = tweet_model.tweet_content\n",
    "    tweet = unicode(tweet, errors='ignore')\n",
    "    tweet = tknzr.tokenize(tweet)\n",
    "\n",
    "    for word in tweet:\n",
    "        word_counter.update([word])\n",
    "        \n",
    "print \"Total Words in DataSet =\", len(word_counter.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words Not Present in GloVe embeddings = 2660\n",
      "Absent Hastags # 1875\n",
      "Absent Other words # 785\n",
      "[(u'#semst', 2914), (u'#gamergate', 61), (u'#god', 54), (u'#lovewins', 48), (u'#wakeupamerica', 38), (u'#scotus', 35), (u'#prolifeyouth', 34), (u'#hillaryclinton', 33), (u'#feminist', 29), (u'#islam', 23), (u'#yesallwomen', 22), (u'#equality', 20), (u'#benghazi', 17), (u'#bible', 16), (u'#ccot', 15), (u'#hillary', 15), (u'#uniteblue', 14), (u'#freethinker', 14), (u'#alllivesmatter', 14), (u'#stophillary2016', 13), (u'#feminists', 13), (u'#climate', 13), (u'#blacklivesmatter', 13), (u'#christian', 12), (u'#womensrights', 12), (u'#mission', 12), (u'#baltimoreriots', 12), (u'#tip', 12), (u'#catholic', 12), (u'#whyimnotvotingforhillary', 12)]\n",
      "[(u\"don't\", 166), (u'...', 156), (u\"it's\", 137), (u\"i'm\", 120), (u\"can't\", 76), (u'2', 52), (u\"you're\", 46), (u\"doesn't\", 44), (u'..', 41), (u\"women's\", 29), (u\"that's\", 28), (u\"she's\", 28), (u\"they're\", 27), (u\"let's\", 27), (u\"isn't\", 26), (u\"what's\", 24), (u\"we're\", 24), (u\"didn't\", 23), (u\"won't\", 23), (u'....', 23), (u'4', 22), (u'2016', 21), (u'1', 20), (u\"there's\", 20), (u\"aren't\", 18), (u\"hillary's\", 18), (u\"i've\", 18), (u\"shouldn't\", 14), (u\"i'll\", 14), (u'7', 13)]\n"
     ]
    }
   ],
   "source": [
    "words_not_in_glove = Counter()\n",
    "\n",
    "for word in word_counter.iterkeys():\n",
    "    if word.lower() not in word_vec_dict:\n",
    "        words_not_in_glove[word] += word_counter[word]\n",
    "\n",
    "print \"Total Words Not Present in GloVe embeddings =\", len(words_not_in_glove.keys())\n",
    "print \"Absent Hastags #\", len([_ for x in words_not_in_glove.keys() if x.startswith(\"#\") == True])\n",
    "print \"Absent Other words #\", len([_ for x in words_not_in_glove.keys() if x.startswith(\"#\") == False])\n",
    "\n",
    "absent_hashtag = Counter()\n",
    "absent_other = Counter()\n",
    "\n",
    "for x in words_not_in_glove.keys():\n",
    "    if x.startswith(\"#\") == True:\n",
    "        absent_hashtag[x] += word_counter[x]\n",
    "    else:\n",
    "        absent_other[x] += word_counter[x]\n",
    "\n",
    "print absent_hashtag.most_common(30)\n",
    "print absent_other.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import TweetTokenizer\n",
    "\n",
    "tknz = TweetTokenizer(strip_handles=True)\n",
    "tknz.tokenize(\"greattttt amazingggggg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
