{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Stance in Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Reading the dataset and pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stances =  set(['FAVOR', 'NONE', 'AGAINST'])\n",
      "Targets =  set(['Atheism', 'Climate Change is a Real Concern', 'Feminist Movement', 'Legalization of Abortion', 'Hillary Clinton'])\n"
     ]
    }
   ],
   "source": [
    "from Model import Model as DataModel\n",
    "\n",
    "dataset = []\n",
    "for filename in [\"../dataset_raw/semeval2016-task6-trialdata.txt\", \"../dataset_raw/semeval2016-task6-trainingdata.txt\"]:\n",
    "    f = open(filename, 'r')\n",
    "    f.readline() # Skip the first line which contains the title\n",
    "\n",
    "    for line in f.readlines():\n",
    "        items = line.strip().split('\\t')\n",
    "        t = DataModel(items[0] , items[1], items[2], items[3])\n",
    "        dataset.append(t)\n",
    "\n",
    "targets = set(map(lambda model:model.target, dataset))\n",
    "stances = set(map(lambda model: model.stance, dataset))\n",
    "\n",
    "print \"Stances = \", stances\n",
    "print \"Targets = \", targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading the Stanford GloVe Twitter Embeddings learned over Twitter data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "glove_word_vec_file = \"../glove.twitter.27B/glove.twitter.27B.200d.txt\"\n",
    "\n",
    "def readGloveData(glove_word_vec_file):\n",
    "    f = open(glove_word_vec_file, 'r')\n",
    "    rawData = f.readlines()\n",
    "    word_vec_dict = {}\n",
    "    for line in rawData:\n",
    "        line = line.strip().split()\n",
    "        tag = line[0]\n",
    "        vec = line[1:]\n",
    "        word_vec_dict[tag] = np.array(vec, dtype=float)\n",
    "            \n",
    "    return word_vec_dict\n",
    "            \n",
    "word_vec_dict = readGloveData(glove_word_vec_file)\n",
    "\n",
    "def getWordVector(word):\n",
    "    if word in word_vec_dict:\n",
    "        return word_vec_dict[word]\n",
    "    return np.zeros_like(word_vec_dict['hi'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocess tweets according to various heuristics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atheism', 'dear', 'lord', 'thank', 'u', 'for', 'all', 'of', 'ur', 'blessings', 'forgive', 'my', 'sins', 'lord', 'give', 'me', 'strength', 'and', 'energy', 'for', 'this', 'busy', 'day', 'ahead', '#blessed', '#hope', '#semst']\n",
      "[-0.3898088   0.53980967 -0.34025896  0.35164412 -0.36131994 -0.42365608\n",
      "  1.1300834  -0.23957048 -0.44593263 -0.11449753 -0.54035536  0.19967907\n",
      " -4.2678372   0.38627892 -0.2171755  -0.08086248  0.13330704 -0.13337536\n",
      "  0.1861204  -0.23284527 -0.21555032  0.1175948  -0.23342282  0.41631888\n",
      " -0.290432  ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "514"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513,)\n",
      "(513, 25)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513, 25) (513,) 396\n",
      "Baseline Prediction (Always 1) : 0.810240963855\n",
      "0.771929824561\n",
      "[[ 41  41]\n",
      " [ 76 355]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X = tweetData\n",
    "Y = tweetClasses\n",
    "\n",
    "print X.shape, Y.shape, Y.sum()\n",
    "\n",
    "#clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1)\n",
    "clf = GaussianNB()\n",
    "cv_prediction = cross_validation.cross_val_predict(clf, X, Y, cv=5)\n",
    "\n",
    "print \"Baseline Prediction (Always 1) : \" + str(538.0/664)\n",
    "\n",
    "print accuracy_score(cv_prediction, Y)\n",
    "print confusion_matrix(cv_prediction, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
